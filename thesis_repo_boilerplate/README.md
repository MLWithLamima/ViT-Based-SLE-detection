# BMR Detection with Vision Transformers (Thesis)

This repository contains code and assets for the thesis **"A Vision Transformer Based Assistive System for Dermatological Diagnosis in SLE"**.
It compares CNN baselines (e.g., ResNet50, DenseNet121, MobileNetV2) with Vision Transformers (e.g., ViT-Small/DeiT) and explores augmentation and CutMix.

## ğŸ“ Suggested Layout
```
repo-root/
â”œâ”€ CNNs_Before_Augmentation/
â”œâ”€ CNNs_After_Augmentation/
â”œâ”€ CNN_with_CutMix/
â”œâ”€ ViTs_Before_Augmentation/
â”œâ”€ ViTs_After_Augmentation/
â”œâ”€ ViTs_with_cutmix/
â”œâ”€ models/                 # place .pth here (tracked by Git LFS) 
â”œâ”€ data/                   # not tracked by git; see below
â”œâ”€ notebooks/              # Jupyter notebooks (optional)
â”œâ”€ src/                    # reusable python code (optional)
â”œâ”€ requirements.txt
â””â”€ README.md
```

> âš ï¸ **Datasets are NOT committed.** Keep raw data outside git or manage with DVC.  
> âš ï¸ **Models (.pth)** are tracked with Git LFS or uploaded as Release assets.

## ğŸ› ï¸ Setup
```bash
python -m venv .venv
# Windows: .venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate

pip install -r requirements.txt
```

## â–¶ï¸ Reproduce (example)
```bash
# train a baseline (example only)
python src/train_cnn.py --arch resnet50 --epochs 50 --data ./data

# evaluate a saved model
python src/eval.py --weights ./models/Suggested_Best_Model.pth --split test
```

## ğŸ”„ Augmentation & CutMix
- Standard augmentations (flip, rotate, color jitter) via Albumentations
- Optional **CutMix** experiments for ViTs/CNNs

## ğŸ“Š Results
Add confusion matrices, ROC curves, and tables here (or link to `results/`).

## ğŸ“¦ Models
- `models/Suggested_Best_Model.pth` (tracked with LFS)  
  Alternatively: upload to **Releases** and link here.

## ğŸ“ Citation
See `CITATION.cff`.

## ğŸ›¡ï¸ License
MIT (see `LICENSE`).